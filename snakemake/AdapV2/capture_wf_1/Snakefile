include: "../Snakefile"
GROUP_BY_UMI_DIR="groupbyumi"
#MIREDAS_DIR="error"
FILTER=f"{CODEC_root}/cmake-build-release/codec filter"
DETECT_DIR="detect"
CONSENSUS_OUT="consensus_out"
RECOVERY = config['duplex_recovery_script']
COLLECT_DUPMET = f"python {RECOVERY}"
UMITOOLS = 'umi_tools'

rule all:
    input:
         expand(DETECT_DIR + "/{index}.detect_fingerprint.txt", index=sample_names),
         #expand("miredas/{index}.cds_consensus.mol_consensus_error_metrics.txt", index=sample_names),
         #expand(Metrics_OUT + "/{index}.duplex_yield_metrics.txt",index=sample_names),
         #expand("accu/{index}.error_metrics.txt", index=sample_names),
          #expand(Metrics_OUT + "/{index}.raw.hs_metrics.txt", index=sample_names),


sample_to_maf = metadata.reset_index().groupby('sample').agg({'fingerprint_maf': set})
sample_to_bait = metadata.reset_index().groupby('sample').agg({'bait_intervals': set})
sample_to_bed = metadata.reset_index().groupby('sample').agg({'bait_bed': set})

rule CollectRawHsMetrics:
    input:
         bam = "tmp/{index}.raw.replacerg.markdup.bam",
    output:
          metrics = Metrics_OUT + "/{index}.raw.hs_metrics.txt",
          per_target_cov = Metrics_OUT  + "/{index}.raw.per_target_cov.txt"
    params:
          ref = REF,
          bait = lambda wildcards: sample_to_bait.loc[wildcards.index]['bait_intervals'],
    resources:
             mem = 16,
             runtime = 12
    shell:
         """
         {PICARD} CollectHsMetrics COVERAGE_CAP=20000 I={input.bam} O={output.metrics} R={params.ref} BAIT_INTERVALS={params.bait} TARGET_INTERVALS={params.bait} PER_TARGET_COVERAGE={output.per_target_cov}
         """

rule RefineUmiGroup:
    input:
         bam = "consensus/{index}.cds_consensus.mol_consensus.aligned.bam"
    output:
         bam = temp("filtered/{index}.cds_consensus.mol_consensus.aligned.umi_tools.bam")
    resources:
         mem = 8,
         runtime = 24
    shell:
        """
            {UMITOOLS} group \
                  --stdin={input.bam} \
                  --stdout={output.bam} \
                  --method=codec \
                  --umi-tag=RX \
                  --umi-tag-delimiter=- \
                  --extract-umi-method=tag \
                  --edit-distance-threshold=2 \
                  --output-bam \
                  --paired \
        """
##CODEC specific filters
rule FilterMolecularConsensusReads:
    input:
        bam = "filtered/{index}.cds_consensus.mol_consensus.aligned.umi_tools.bam"
    output:
        bam = "filtered/{index}.cds_consensus.mol_consensus.filtered.bam",
        bai = "filtered/{index}.cds_consensus.mol_consensus.filtered.bam.bai"
    resources:
        mem = 8,
        runtime = 24
    shell:
        """
        {FILTER} -b {input.bam} -f 2 | samtools sort - -o {output.bam} && samtools index {output.bam}  
        """

rule CDSErrorMetrics:
    input:
        bam = "filtered/{index}.cds_consensus.mol_consensus.filtered.bam"
    output:
        accu =  "accu/{index}.error_metrics.txt",
        error =  "accu/{index}.mutant_families.txt",
        context = "accu/{index}.context_count.txt",
    params:
        ref = REF,
        high_conf_region = lambda wildcards : sample_to_bed.loc[wildcards.index]['bait_bed'],
        germ_vcf = lambda wildcards : sample_to_vcf.loc[wildcards.index]['germline_vcf'],
        germ_bam = lambda wildcards : sample_to_germbam.loc[wildcards.index]['germline_bam'],
        mut_maf = lambda wildcards: sample_to_maf.loc[wildcards.index]['fingerprint_maf'],
    resources:
        mem = 8,
        runtime = 96
    shell:
        """
           {ACCU_BIN}  -b {input.bam} \
               -L {params.high_conf_region} \
               -r {params.ref} \
               -n {params.germ_bam} \
               -m 60 \
               -q 30 \
               -d 12 \
               -V {params.germ_vcf} \
               -M {params.mut_maf} \
               -x 2 \
               -5 \
               -g 30 \
               -G 250 \
               -Q 0.6 \
               -N 0.03 \
               -B 0.5 \
               -Y 0 \
               -a {output.accu} \
               -e {output.error} \
               -C {output.context}
        """


rule MiredasDetectFingerprint:
    input:
         bam = "filtered/{index}.cds_consensus.mol_consensus.filtered.bam"
    output:
         detect = DETECT_DIR + "/{index}.detect_fingerprint.txt",
         families = DETECT_DIR + "/{index}.detect_families.txt"
    params:
         ref = REF,
         mut_maf = lambda wildcards: sample_to_maf.loc[wildcards.index]['fingerprint_maf'],
    resources:
         mem = 4,
         runtime = 2
    shell:
        """
        miredas DetectFingerprint \
            -r {params.ref} \
            -b {input.bam} \
            -m {params.mut_maf} \
            -o {output.detect} \
            --min_base_quality 30 \
            -df edit_distance \
            --mutant_families_outfile {output.families} \
        """

rule MiredasErrorMetrics2:
    input:
           bam = "filtered/{index}.cds_consensus.mol_consensus.filtered.bam"
    output:
          "miredas/{index}.cds_consensus.mol_consensus_error_metrics.txt",
          "miredas/{index}.cds_consensus.mol_consensus_mutant_families.txt",
          "miredas/{index}.cds_consensus.mol_consensus_trinucleotide_context.txt"
    params:
          normal_bam = lambda wildcards: sample_to_germbam.loc[wildcards.index]['germline_bam'],
          sample_id = "{index}",
          germ_vcf = lambda wildcards: sample_to_vcf.loc[wildcards.index]['germline_vcf'],
          interval_list = lambda wildcards: sample_to_bait.loc[wildcards.index]['bait_intervals'],
          mut_maf = lambda wildcards: sample_to_maf.loc[wildcards.index]['fingerprint_maf'],
          output = "miredas/{index}.cds_consensus.mol_consensus",
          ref = REF,
          max_af = 1.0,
    resources:
             mem = 14,
             runtime = 72,
    shell:
        """
        miredas CollectErrorMetrics2 \
            -b {input.bam} \
            -n {params.normal_bam} \
            -s {params.sample_id} \
            -m {params.mut_maf} \
            -i {params.interval_list} \
            -r {params.ref} \
            --output_mutant_families \
            --het_vcf {params.germ_vcf} \
            --max_af {params.max_af} \
            --min_base_quality 30 \
           -o {params.output} \
        """

rule GetContextErrorRate:
    input:
        mutfam = "miredas/{index}.cds_consensus_mutant_families.txt",
        tnd = "miredas/{index}.cds_consensus_trinucleotide_context.txt"
    output:
        "miredas/{index}.cds_consensus_error_monomer.txt",
    wildcard_constraints:
        batch_id="[0-9a-zA-Z_]+",
        index="[0-9a-zA-Z_]+ctDNA"
    shell:
         """
           {MONOMER_ERROR_SCRIPT} --tnd  {input.tnd} --mutfam {input.mutfam} > {output}
         """

rule CollectRawInsertSizeMetrics:
    input:
         bam = "tmp/{batch_id}.{index}.raw.aligned.bam",
    output:
          txt = Metrics_OUT + "/{batch_id}.{index}.raw.insert_size_metrics.txt",
          hist = Metrics_OUT + "/{batch_id}.{index}.raw.insert_size_histogram.pdf"
    params:
          ref = REF
    shell:
         """
         {PICARD} CollectInsertSizeMetrics I={input.bam} O={output.txt} H={output.hist} M=0.5 W=900 DEVIATIONS=100
         """

rule SortGBUbam:
    input:
        GROUP_BY_UMI_DIR + "/{index}.raw.GroupedByUmi.bam",
    output:
        bam = GROUP_BY_UMI_DIR + "/{index}.sorted.GroupedByUmi.bam",
        bai = GROUP_BY_UMI_DIR + "/{index}.sorted.GroupedByUmi.bai",
    resources:
        mem = 12,
        runtime = 12
    shell:
        """
        {PICARD} SortSam I={input} O={output.bam} SO=coordinate CREATE_INDEX=true MAX_RECORDS_IN_RAM=1000000
        """

rule GroupRawReadByUMI:
    input:
        "tmp/{index}.raw.replacerg.markdup.bam",
    output:
        bam = GROUP_BY_UMI_DIR + "/{index}.raw.GroupedByUmi.bam",
        histogram = Metrics_OUT + "/{index}.raw.umiHistogram.txt"
    resources:
        mem = 16,
        runtime = 48
    shell:
        """
        {FGBIO} GroupReadsByUmi \
            -i {input} \
            -o {output.bam} \
            -f {output.histogram} \
            --strategy=edit \
        """

rule DuplexRecoveryByTarget:
    input:
         GROUP_BY_UMI_DIR + "/{index}.raw.GroupedByUmi.bam",
    output:
         Metrics_OUT + "/{index}.duplex_yield_metrics.txt",
    resources:
         mem = 8,
         runtime = 12
    params:
         interval = lambda wildcards: sample_to_bait.loc[wildcards.index]['bait_intervals'],
    shell:
         """
         {COLLECT_DUPMET} --bam_file {input} \
             -l {params.interval} \
             --min_reads 1 \
             -c \
             -p \
             -r \
             -o {output}
         """

#rule CollectAllMetrics:
#    input:
